---
title: "Usage"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

_This package is under heavy development. Please do not use this package for actual reserach._

```{r setup, eval = F}
suppressWarnings(suppressPackageStartupMessages(library(sumR)))
```

First we load up some example data. Here we have 4 injection of which 1 is a blank sample, all with negative polarity. These files have spectra which are combined together and centroided. 
```{r files, eval = F}
dir <- file.path(r"(F:\stem_cell_blank_cell_samples)")
```

## Converting vendor format
To convert your vendor to mzML, we can use the `rawToMzml` function. 

```{r eval = F}
files <- rawToMzml(dir, output = file.path(getwd(), "test2"), rt = c(60, 420))
```

## Defining Metadata

```{r, eval = F}
df <- read.csv("metadata.csv", row.names = 1)
df
```

## Peak picking
Cells measured using DI-MS can be analyzed using the spectrum-based peak picking. 

```{r peakPicking, eval = F}
peaks <- peakPicking(list.files(dir, pattern = ".mzML", full.names = T),
                     massDefect = F, massWindow = 200, polarity = "-")
```

```{r peakPlot, eval = F}
filteredPeaks <- peakFilter(peaks, SNR = 1, intensity = 1e4)
plotSpectrumPeaks(filteredPeaks, file = 1, scan = 2)
plotSpectrumPeaks(filteredPeaks, file = 14, scan = 4)
noisePlot(filteredPeaks, file = 1)
plotCellPeaks(filteredPeaks, file = 1)
```




## Spectra Alignment

```{r eval = F}
spectra <- binSpectra(peaks, npeaks = 5, method = "mean", tolerance = 1e-4)
```


```{r eval = F}
plotSpectraShift(spectra, 30)
```

## Cell Alignment

```{r eval = F}
cells <- binCells(spectra, cellData = df, phenotype = "phenotype", tolerance = 1e-4)
```

```{r eval = F}
plotCellShift(cells)
```

```{r, eval = F}
exp <- blankSubstraction(cells) %>%
  isotopeTagging() %>%
  imputation(method = "noise")
 # setMetadata(polarity = "+")
```

## Modelling & Statistics
* Combining polarities
* Variable feature selection
* Shapiro test for normality
* Levene test for variance
* Welch test for significant difference
* Fold change for log difference
* Model generation to retrieve feature importance

```{r, eval = F}
expModel <- #combineExperiments(exp, exp2) %>%
  #keepVariableFeatures(top = 200) %>%
  exp %>%
  shapiroTest() %>% # Just flagging
  leveneTest(filter = TRUE) %>% # Just flagging
  welchTest() %>%
  foldChange() %>%
  generateModel(modelName = "rf", seed = 42) %>%
  generateModel(modelName = "glmnet", seed = 42)
```


## Model Assessment
```{r assessment, eval = F}
print(model(expModel, "rf")$confMatrix)
print(model(expModel, "glmnet")$confMatrix)
```

## Plot
```{r pca, eval = F, fig.width=6}
sumR:::plotFeatureSds(expModel)
samplePCA(expModel)
compoundPCA(expModel)
screePCA(expModel)
plotUMAP(expModel, components = 30)
```

```{r CV, eval = F, fig.width=6}
plotCrossValidation(expModel, "rf")
plotCrossValidation(expModel, "glmnet") 
```

## SessionInfo

```{r sessionInfo}
sessionInfo()
```
