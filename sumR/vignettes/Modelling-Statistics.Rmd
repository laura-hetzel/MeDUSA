---
title: "Modelling & Statistics"
author:
- name: Pascal Maas
  affiliation: >
   Leiden Academic Centre for Drug Research, 
   Leiden University, Netherlands
  email: p.maas@lacdr.leidenuniv.nl
  
date: "`r Sys.Date()`"
output: 
  html_document:
      theme: united
      highlight: tango
vignette: >
  %\VignetteIndexEntry{Modelling & Statistics}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
suppressPackageStartupMessages(library(sumR))
```

`sumR` supports building models to determine phenotypes that might be discriminatory. The package includes several univariate tests, as well as multivariate tests using models in the [caret package](https://topepo.github.io/caret/). Finally we can inspect the results using PCA, UMAP and other plots.

### Univariate statistical tests

sumR supports the shapiro-wilk test for normality, levene test for difference in variance between groups, and welch T-test for significant difference testing between groups. These tests will test the features (row-wise), not samples. Finally, while not a statistical test, the fold change between the given phenotype can be calculated.

```{r statTests}
expModel <- expModel %>%
  shapiroTest() %>%
  leveneTest() %>% 
  welchTest() %>%
  foldChange()

  # TODO: Plot each of these in appropriate plots
```

### Filter non-variable features

Due to the drop-out effect, a large amount of values need to be imputed. Generally, this causes these features to have a low variance and consequently a low impact on models. With the function `keepVariableFeatures()` we can subset the found features based on their variance, determined by the `leveneTest()` function. Using the `plotFeatureSds()` function we can inspect the standard deviation of each feature in a barplot.

```{r variableFeatures}
expModel <- keepVariableFeatures(expModel)
plotFeatureSds(expModel)
```

### Data inspection using PCA & UMAP

The results can be inspected using several plot types. `samplePCA()` is a function that plots a Principle Components Analysis (PCA) on the samples. In contrast, the `compoundPCA()` function plots a PCA for the compounds instead. Next, the `screePCA()` function plots a barplot with the variance explained for each Principle Component (PC). Finally, we can use the `plotUMAP()` function to plot a UMAP after doing a PCA first. This function takes in the number of PCs to construct the UMAP.

```{r pcaPlots}
samplePCA(expModel)
compoundPCA(expModel)
screePCA(expModel)
plotUMAP(expModel, components = 10)
```

### Model generation

As stated before, sumR utilizes the caret package to generate models. The 'Available Models' section in the caret documentation indicates which models are available (you may need to install dependencies for some models). The `generateModel()` function has the following workflow:

1.  Data partitioning in a train/test set
2.  Set the train control with scaling and centering
3.  Perform training with cross-validation
4.  Predict on the partitioned test set
5.  Produce a confusion matrix and determine important variables

the generateModel function takes in the following parameters:

-   exp: The SummarizedExperiment object
-   assay: The assay to use (should be an assay without missing values)
-   modelName: Name of the model to use as defined by `caret`
-   folds: Number of folds to use for cross-validation
-   ratio: Ratio of train-test data split
-   seed: Used for reproducible results

```{r models}
expModel <- generateModel(
    exp = expModel,
    assay = "Imputed",
    modelName = "rf", 
    folds = 5, 
    ratio = 0.632,
    seed = 42
) 
```

All generated models are stored in the metadata of the SummarizedExperiment object under `model`.

### Model Assessment

Using the `model()` function, information about a given model can be accessed. It will return a list with the following entries: `train`, `test`, `model`, `prediction`, `varImp`, and `confMatrix`. These can be used to assess the quality of the model for the given phenotype. Here we are printing the confusion matrix.

```{r assessment}
print(model(expModel, "rf")$confMatrix)

# TODO: Plot the ROC, Varimportance, scatterplot (PCA?) with predictions, etc. 
```

### Cross validation

We can also inspect the performance of each model by plotting the accuracy during cross validation. This is done by the `plotCrossValidation()` function with a given model name.

```{r CV}
plotCrossValidation(expModel, "rf")
```
